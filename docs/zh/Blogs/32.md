# StreamNative Orca Agent Engine 是什么

2025年9月，StreamNative 发布了 Orca Agent Engine，目前处于私有预览阶段。Orca 不是一个 Agent 框架，而是一个为生产环境部署 AI Agent 设计的基础设施层。简单说，它解决的是"如何把 Agent 从实验室的原型部署到生产环境"这个问题。

市面上已经有很多 Agent 开发框架，比如 LangChain、OpenAI Agents SDK、Google ADK。这些框架帮助开发者快速构建 Agent 原型，但当你想把 Agent 部署到生产环境时，会遇到很多基础设施问题：如何让 Agent 持续在线？如何管理 Agent 的状态？如何让多个 Agent 协作？如何监控和治理这些自主运行的系统？Orca 就是为了解决这些问题而存在的。

## 核心架构

Orca 的架构可以理解为**事件总线 + Agent 运行时**的组合。底层使用 Pulsar 或 Kafka 作为共享事件总线，所有 Agent 通过这个总线进行通信。Agent 订阅感兴趣的 topic，处理事件，然后将结果发布到其他 topic。这形成了一个事件驱动的交互网络。

在事件总线之上，Orca 提供了托管的 Agent 运行环境。开发者打包自己的 Agent 代码部署上去，Orca 负责生命周期管理、状态持久化、工具调用、监控和治理。Agent 代码本身只需要专注业务逻辑，不需要处理消息订阅、反序列化、错误重试这些基础设施的事情。

这和直接使用 Kafka 或 Pulsar 的区别在于，Orca 做了很多 Agent 特定的优化。比如持久化的流式内存，让 Agent 可以在多轮对话中保持上下文。比如 MCP 工具集成，让 Agent 可以动态发现和使用各种外部工具。比如异步 LLM 调用支持，让 Agent 调用大模型时不会阻塞整个事件循环。这些都是通用消息队列不提供的能力。

Orca 基于 Apache Pulsar 的 Serverless 计算基础（Pulsar Functions）演化而来。Pulsar Functions 已经在生产环境中验证过可靠性，Orca 在此基础上增加了 AI Agent 特定的功能。运行在 Orca 上的 Agent 自动继承 StreamNative Cloud 的弹性扩展、多租户隔离、高可用性等企业级能力。

## 从无状态到有状态

传统的 Agent 大多是无状态的请求-响应模式。用户发送一个请求，Agent 处理后返回响应，然后忘记一切。下次请求来的时候，Agent 不记得之前发生过什么。

Orca 将 Agent 转变为持续在线的有状态服务。Agent 可以维护持久化的流式内存，在对话和交互之间保持上下文。这是实现真正自主 Agent 的关键能力。想象一个客服 Agent，它需要记住客户之前的问题、偏好、购买历史。或者一个监控 Agent，它需要追踪系统状态的变化趋势。

状态管理与 StreamNative Cloud 的扩展和租户能力深度集成。Agent 的状态持久化在事件流中，可以在重启、迁移或故障恢复后继续工作。这种设计让 Agent 可以像微服务一样可靠运行。

## MCP 工具集成

Orca 深度集成了 Model Context Protocol (MCP)，这是 Anthropic 推出的开放协议。通过 MCP，Agent 可以安全地使用各种外部工具：调用 REST API、查询数据库、读取实时数据流、调用云服务、甚至用自然语言管理基础设施。

StreamNative 开发了自己的 MCP Server（开源组件），将 Pulsar/Kafka 事件流与外部工具和 API 桥接起来。开发者定义工具的接口、认证方式、参数 schema，任何 Agent 都可以在需要时动态发现和使用这个工具。不需要为每个集成编写自定义粘合代码，也不用担心凭证泄露。

一个典型场景是用自然语言管理 Pulsar 集群。用户可以对 Agent 说"将 topic 'user-signups' 的保留时间增加到 3 天"，Agent 通过 MCP 自动调用 Pulsar 的管理 API 执行操作。或者说"显示所有 topic 的消费者 lag"，Agent 会查询集群状态并返回结果。

## 框架无关和编排

Orca 支持多种 Agent 框架，包括 Google ADK、OpenAI Agents SDK，以及普通的 Python 代码。开发者可以直接打包现有的 Agent 代码部署，无需修改。LangGraph 等其他框架的支持也在路线图中。这意味着开发者不会被锁定在某个特定框架上。

Orca 提供了灵活的编排能力。可以将多个 Agent 串联执行，一个的输出是另一个的输入。可以并行运行多个 Agent 处理不同的任务。可以根据规则或事件动态调整执行路径。这使得构建复杂的事件驱动架构变得简单。

一个订单处理系统可能需要多个 Agent 协作：库存检查 Agent、支付处理 Agent、物流调度 Agent、通知发送 Agent。Orca 可以根据订单的状态和事件，动态协调这些 Agent 的执行。每个 Agent 专注自己的职责，通过事件总线协作。

## 治理和可观测性

对于生产环境的 AI Agent，治理和可观测性是必需的。Orca 提供了完整的监控能力，可以端到端追踪事件流、测量 Agent 延迟、捕获异常、可视化 Agent 的交互和决策路径。

治理方面，Orca 支持 RBAC（基于角色的访问控制）、安全的密钥管理、审计日志、版本控制和灰度发布。在紧急情况下，可以一键暂停 Agent 的自主性或禁用其事件订阅。需要调试时，可以重放 Agent 的事件输入，复现其行为，或者检查 Agent 的状态日志，理解其决策过程。

这些能力让企业可以在保持必要监督和控制的前提下，部署自主运行的 Agent。

## Agent 网格

Orca 的长期愿景是创建"Agent 网格"（Agent Mesh）。在这个网格中，多个自主 Agent 通过事件总线连接，可以动态发现和调用其他 Agent 的能力，可以共享上下文和状态，可以协作完成复杂任务。整个系统是自组织、自修复的。

这类似于微服务架构中的 Service Mesh，但是专门为 AI Agent 设计。Agent 网格提供了通信、发现、治理、可观测性的统一基础设施，让开发者可以专注于 Agent 的业务逻辑，而不是基础设施的搭建。

一个典型的应用场景是自主事件响应系统。监控 Agent 持续监听系统指标事件，检测到异常后触发诊断 Agent 分析日志确定根因，然后修复 Agent 自动重启问题服务并调整资源配额，最后通知 Agent 向运维团队发送报告。整个过程在几秒钟内完成，多个 Agent 通过事件总线自动协调。

## 当前状态

Orca 于 2025 年 9 月 30 日进入私有预览阶段，首先在 BYOC（Bring Your Own Cloud）部署中提供。目前支持 Google ADK 和 OpenAI Agents SDK，未来几个月将扩展到所有部署模式。组织可以通过 StreamNative 客户团队加入预览计划。

作为一个新产品，Orca 的生产就绪性还需要时间验证。市场是否真的需要专门的 Agent 基础设施，还是通用的 Serverless 加消息队列就够了，这也需要观察。但至少在技术方向上，Orca 提供了一个清晰的答案：在事件驱动的消息队列之上，构建专门服务 AI Agent 的基础设施层。

## 本质

Orca 本质上是把消息队列（Pulsar/Kafka）定位为 AI Agent 的通信基础设施，而不是让每个 Agent 各自为战。通过统一的事件驱动架构，多个 Agent 可以形成协作网络。Orca 在事件总线之上加了一层专门服务 Agent 的运行时环境，提供状态管理、工具集成、编排、治理等能力。

这是 StreamNative 在 AI 方向最激进的产品，代表了从"支持 AI"到"为 AI 重新设计基础设施"的转变。它试图解决当前 AI Agent 部署的核心问题：数据分散、管道脆弱、Agent 进程孤立。是否成功，时间会给答案。