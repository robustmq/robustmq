// Copyright 2023 RobustMQ Team
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use std::fmt::Debug;
use std::ops::RangeBounds;
use std::sync::Arc;

use super::{cf_raft_logs, cf_raft_store, id_to_bin, StorageResult};
use crate::core::metrics::{
    metrics_rocksdb_storage_err_inc, metrics_rocksdb_storage_total_inc,
    metrics_rocksdb_stroge_total_ms, RocksDBLabels,
};
use crate::raft::store::bin_to_id;
use crate::raft::typeconfig::TypeConfig;
use common_base::tools::now_mills;
use openraft::storage::{IOFlushed, RaftLogStorage};
use openraft::{
    AnyError, Entry, ErrorSubject, ErrorVerb, LogId, LogState, OptionalSend, RaftLogReader,
    StorageError, Vote,
};
use rocksdb::{BoundColumnFamily, Direction, DB};

#[derive(Debug, Clone)]
pub struct LogStore {
    pub db: Arc<DB>,
}

impl LogStore {
    fn store(&self) -> Arc<BoundColumnFamily> {
        self.db.cf_handle(&cf_raft_store()).unwrap()
    }

    fn logs(&self) -> Arc<BoundColumnFamily> {
        self.db.cf_handle(&cf_raft_logs()).unwrap()
    }

    fn flush(
        &self,
        subject: ErrorSubject<TypeConfig>,
        verb: ErrorVerb,
    ) -> Result<(), StorageError<TypeConfig>> {
        metrics_rocksdb_storage_total_inc(RocksDBLabels::log("flush"));
        let start_ms = now_mills();

        self.db.flush_wal(true).map_err(|e| {
            metrics_rocksdb_storage_err_inc(RocksDBLabels::log("flush"));
            StorageError::new(subject, verb, AnyError::new(&e))
        })?;

        metrics_rocksdb_stroge_total_ms(
            RocksDBLabels::log("flush"),
            (now_mills() - start_ms) as f64,
        );
        Ok(())
    }

    fn get_last_purged_(&self) -> StorageResult<Option<LogId<TypeConfig>>> {
        metrics_rocksdb_storage_total_inc(RocksDBLabels::log("get"));
        Ok(self
            .db
            .get_cf(&self.store(), b"last_purged_log_id")
            .map_err(|e| {
                metrics_rocksdb_storage_err_inc(RocksDBLabels::log("get"));

                StorageError::read(&e)
            })?
            .and_then(|v| serde_json::from_slice(&v).ok()))
    }

    fn set_last_purged_(&self, log_id: LogId<TypeConfig>) -> StorageResult<()> {
        metrics_rocksdb_storage_total_inc(RocksDBLabels::log("set"));
        self.db
            .put_cf(
                &self.store(),
                b"last_purged_log_id",
                serde_json::to_vec(&log_id).unwrap().as_slice(),
            )
            .map_err(|e| {
                metrics_rocksdb_storage_err_inc(RocksDBLabels::log("set"));

                StorageError::write(&e)
            })?;

        self.flush(ErrorSubject::Store, ErrorVerb::Write)?;
        Ok(())
    }

    fn set_committed_(
        &self,
        committed: &Option<LogId<TypeConfig>>,
    ) -> Result<(), StorageError<TypeConfig>> {
        metrics_rocksdb_storage_total_inc(RocksDBLabels::log("set"));
        let json = serde_json::to_vec(committed).unwrap();

        self.db
            .put_cf(&self.store(), b"committed", json)
            .map_err(|e| {
                metrics_rocksdb_storage_err_inc(RocksDBLabels::log("set"));

                StorageError::write(&e)
            })?;

        self.flush(ErrorSubject::Store, ErrorVerb::Write)?;
        Ok(())
    }

    fn get_committed_(&self) -> StorageResult<Option<LogId<TypeConfig>>> {
        metrics_rocksdb_storage_total_inc(RocksDBLabels::log("get"));
        Ok(self
            .db
            .get_cf(&self.store(), b"committed")
            .map_err(|e| {
                metrics_rocksdb_storage_err_inc(RocksDBLabels::log("get"));

                StorageError::read(&e)
            })?
            .and_then(|v| serde_json::from_slice(&v).ok()))
    }

    fn set_vote_(&self, vote: &Vote<TypeConfig>) -> StorageResult<()> {
        metrics_rocksdb_storage_total_inc(RocksDBLabels::log("set"));
        self.db
            .put_cf(&self.store(), b"vote", serde_json::to_vec(vote).unwrap())
            .map_err(|e| {
                metrics_rocksdb_storage_err_inc(RocksDBLabels::log("set"));

                StorageError::write_vote(&e)
            })?;

        self.flush(ErrorSubject::Vote, ErrorVerb::Write)?;
        Ok(())
    }

    fn get_vote_(&self) -> StorageResult<Option<Vote<TypeConfig>>> {
        metrics_rocksdb_storage_total_inc(RocksDBLabels::log("get"));
        Ok(self
            .db
            .get_cf(&self.store(), b"vote")
            .map_err(|e| {
                metrics_rocksdb_storage_err_inc(RocksDBLabels::log("get"));

                StorageError::write_vote(&e)
            })?
            .and_then(|v| serde_json::from_slice(&v).ok()))
    }
}

impl RaftLogReader<TypeConfig> for LogStore {
    async fn try_get_log_entries<RB: RangeBounds<u64> + Clone + Debug + OptionalSend>(
        &mut self,
        range: RB,
    ) -> StorageResult<Vec<Entry<TypeConfig>>> {
        let start = match range.start_bound() {
            std::ops::Bound::Included(x) => id_to_bin(*x),
            std::ops::Bound::Excluded(x) => id_to_bin(*x + 1),
            std::ops::Bound::Unbounded => id_to_bin(0),
        };

        metrics_rocksdb_storage_total_inc(RocksDBLabels::log("get"));
        self.db
            .iterator_cf(
                &self.logs(),
                rocksdb::IteratorMode::From(&start, Direction::Forward),
            )
            .map(|res| {
                let (id, val) = res.unwrap();
                let entry: StorageResult<Entry<_>> = serde_json::from_slice(&val).map_err(|e| {
                    metrics_rocksdb_storage_err_inc(RocksDBLabels::log("get"));

                    StorageError::read_logs(&e)
                });
                let id = bin_to_id(&id);

                assert_eq!(Ok(id), entry.as_ref().map(|e| e.log_id.index));
                (id, entry)
            })
            .take_while(|(id, _)| range.contains(id))
            .map(|x| x.1)
            .collect()
    }

    async fn read_vote(&mut self) -> Result<Option<Vote<TypeConfig>>, StorageError<TypeConfig>> {
        self.get_vote_()
    }
}

impl RaftLogStorage<TypeConfig> for LogStore {
    type LogReader = Self;

    async fn get_log_state(&mut self) -> StorageResult<LogState<TypeConfig>> {
        metrics_rocksdb_storage_total_inc(RocksDBLabels::log("get"));
        let last = self
            .db
            .iterator_cf(&self.logs(), rocksdb::IteratorMode::End)
            .next()
            .and_then(|res| {
                let (_, ent) = res.unwrap();
                Some(
                    serde_json::from_slice::<Entry<TypeConfig>>(&ent)
                        .ok()?
                        .log_id,
                )
            });

        let last_purged_log_id = self.get_last_purged_()?;

        let last_log_id = match last {
            None => last_purged_log_id,
            Some(x) => Some(x),
        };
        Ok(LogState {
            last_purged_log_id,
            last_log_id,
        })
    }

    async fn save_committed(
        &mut self,
        _committed: Option<LogId<TypeConfig>>,
    ) -> Result<(), StorageError<TypeConfig>> {
        self.set_committed_(&_committed)?;
        Ok(())
    }

    async fn read_committed(
        &mut self,
    ) -> Result<Option<LogId<TypeConfig>>, StorageError<TypeConfig>> {
        let c = self.get_committed_()?;
        Ok(c)
    }

    #[tracing::instrument(level = "trace", skip(self))]
    async fn save_vote(&mut self, vote: &Vote<TypeConfig>) -> Result<(), StorageError<TypeConfig>> {
        self.set_vote_(vote)
    }

    #[tracing::instrument(level = "trace", skip_all)]
    async fn append<I>(&mut self, entries: I, callback: IOFlushed<TypeConfig>) -> StorageResult<()>
    where
        I: IntoIterator<Item = Entry<TypeConfig>> + Send,
        I::IntoIter: Send,
    {
        metrics_rocksdb_storage_total_inc(RocksDBLabels::log("set"));
        for entry in entries {
            let id = id_to_bin(entry.log_id.index);
            assert_eq!(bin_to_id(&id), entry.log_id.index);
            self.db
                .put_cf(
                    &self.logs(),
                    id,
                    serde_json::to_vec(&entry).map_err(|e| StorageError::write_logs(&e))?,
                )
                .map_err(|e| {
                    metrics_rocksdb_storage_err_inc(RocksDBLabels::log("set"));

                    StorageError::write_logs(&e)
                })?;
        }

        callback.io_completed(Ok(()));

        Ok(())
    }

    #[tracing::instrument(level = "debug", skip(self))]
    async fn truncate(&mut self, log_id: LogId<TypeConfig>) -> StorageResult<()> {
        tracing::debug!("delete_log: [{:?}, +oo)", log_id);
        metrics_rocksdb_storage_total_inc(RocksDBLabels::log("delete"));

        let from = id_to_bin(log_id.index);
        let to = id_to_bin(0xff_ff_ff_ff_ff_ff_ff_ff);
        self.db
            .delete_range_cf(&self.logs(), &from, &to)
            .map_err(|e| {
                metrics_rocksdb_storage_err_inc(RocksDBLabels::log("delete"));

                StorageError::write_logs(&e)
            })
    }

    #[tracing::instrument(level = "debug", skip(self))]
    async fn purge(&mut self, log_id: LogId<TypeConfig>) -> Result<(), StorageError<TypeConfig>> {
        tracing::debug!("delete_log: [0, {:?}]", log_id);
        metrics_rocksdb_storage_total_inc(RocksDBLabels::log("delete"));

        self.set_last_purged_(log_id)?;
        let from = id_to_bin(0);
        let to = id_to_bin(log_id.index + 1);
        self.db
            .delete_range_cf(&self.logs(), &from, &to)
            .map_err(|e| {
                metrics_rocksdb_storage_err_inc(RocksDBLabels::log("delete"));

                StorageError::write_logs(&e)
            })
    }

    async fn get_log_reader(&mut self) -> Self::LogReader {
        self.clone()
    }
}
